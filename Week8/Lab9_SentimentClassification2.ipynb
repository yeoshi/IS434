{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Lab 9 - Sentiment Classification\n",
    "\n",
    "In this script, we will build Naive Bayes classification model for\n",
    "predicting sentiment (positive or negative).\n",
    "\n",
    "Dataset: NLTK package comes with sample datasets. We use \"movie reviews\" dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 80%/20% split for Training/Testing\n",
    "SPLIT = 0.8\n",
    "\n",
    "# Stop Words filtering\n",
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the IMDB dataset\n",
    "print(movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    feats = defaultdict(lambda: False)\n",
    "    for word in words:\n",
    "        # Filter out Stop Words\n",
    "        if word not in stopset:\n",
    "            feats[word] = True\n",
    "    return feats\n",
    "\n",
    "\n",
    "def evaluate_classifier():\n",
    "\n",
    "    # Let's go to IMDB movie dataset and obtain IDs.\n",
    "    # IDs of those movies with POSITIVE sentiment label.\n",
    "    # IDs of those movies with NEGATIVE sentiment label.\n",
    "    negids = movie_reviews.fileids('neg')\n",
    "    posids = movie_reviews.fileids('pos')\n",
    "\n",
    "    # Remember \"Bag of Words\"?\n",
    "    # We're going to generate that bag-of-words \"feature set\".\n",
    "    negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "    posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "    # Now, we need to split our dataset into 80% training and 20% testing.\n",
    "    cutoff = int(len(posfeats) *SPLIT)\n",
    "    trainfeats = negfeats[:cutoff] + posfeats[:cutoff]\n",
    "    testfeats = negfeats[cutoff:] + posfeats[cutoff:]\n",
    "\n",
    "    # Let's see how many data points we have in TRAINING dataset and in TESTING dataset.\n",
    "    print ('Train on %d instances\\nTest on %d instances' % (len(trainfeats), len(testfeats)))\n",
    "\n",
    "    ##### OKAY, we're done with feature preparation ######\n",
    "\n",
    "    ##### We're ready to build a Naive Bayes classifier #####\n",
    "    # Let's train our model - based on the TRAINING dataset\n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "    # Now let's feed in TESTING dataset and compute accuracy\n",
    "    print ('Accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "\n",
    "    # Which features were most informative?\n",
    "    classifier.show_most_informative_features()\n",
    "\n",
    "    # Now, let's draw a confusion matrix\n",
    "    pos = [classifier.classify(fs) for (fs, l) in posfeats[cutoff:]]\n",
    "    pos = np.array(pos)\n",
    "    neg = [classifier.classify(fs) for (fs, l) in negfeats[cutoff:]]\n",
    "    neg = np.array(neg)\n",
    "\n",
    "    # We're done classifying... let's see the results\n",
    "    print ('Confusion Matrix')\n",
    "    print ('\\t\\t', 'Predicted Class')\n",
    "    print ('-'*40)\n",
    "\n",
    "    print ('|\\t %d (TP) \\t|\\t %d (FN) \\t| Actual class' % ((pos == 'pos').sum(), (pos == 'neg').sum()))\n",
    "    print ('|\\t %d (FP) \\t|\\t %d (TN) \\t|' % ((neg == 'pos').sum(), (neg == 'neg').sum()))\n",
    "\n",
    "    print ('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# MAIN #################\n",
    "evaluate_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
