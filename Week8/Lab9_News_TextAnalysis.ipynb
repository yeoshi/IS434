{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lab 9\n",
    "\n",
    "In this script, we will clean textual data and draw a word cloud\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the packages\n",
    "# nltk - natural langauge processing\n",
    "# wordcloud - for drawing word cloud\n",
    "# matplotlib - for charting\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 1 ###############\n",
    "\n",
    "# Specify input file\n",
    "news_article_path = 'StraitsTimes1.txt'\n",
    "\n",
    "# Open the file, read in all the news content and make a single sentence.\n",
    "news_article_file = open(news_article_path, 'r')\n",
    "news_content = ''\n",
    "# Read one line at a time\n",
    "for line in news_article_file:\n",
    "    if len(line.strip()) > 0:\n",
    "        news_content = news_content + line + ' '\n",
    "\n",
    "# See what it looks like.\n",
    "print (news_content)\n",
    "\n",
    "# Let's lower-case all words.\n",
    "news_content = news_content.lower()\n",
    "\n",
    "# See what it looks like.\n",
    "print (news_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 2 ###############\n",
    "# sent_tokenize() function takes a text blob and breaks it into 'sentences'.\n",
    "news_sentences = sent_tokenize(news_content)\n",
    "print (news_sentences)\n",
    "# How many sentences are in this news article?\n",
    "print (len(news_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 3 ###############\n",
    "# word_tokenize() function takes a text blob and breaks it into 'words'.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#news_words = word_tokenize(news_content)\n",
    "news_words = tokenizer.tokenize(news_content)\n",
    "print (news_words)\n",
    "# How many words are in this news article?\n",
    "print (len(news_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 4 ###############\n",
    "# Let's load up English corpus from NLTK package.\n",
    "stop_words = stopwords.words('english')\n",
    "# See what words are inside.\n",
    "print (stop_words)\n",
    "'''\n",
    "stop_words.remove('me')\n",
    "#print(stop_words)\n",
    "stop_words.append('grace')\n",
    "print(stop_words)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 5 ###############\n",
    "# Let's remove stop words from the news content.\n",
    "#news_words_filtered = [w for w in news_words if not w in stop_words]\n",
    "\n",
    "news_words_filtered = []\n",
    "\n",
    "for w in news_words:\n",
    "    if w not in stop_words:\n",
    "        news_words_filtered.append(w)\n",
    "\n",
    "# After removing stop words, how many words remain?\n",
    "print (len(news_words_filtered))\n",
    "print(news_words_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 6 ###############\n",
    "# Let's create a Porter Stemmer object.\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Let's test out this stemmer.\n",
    "some_words = [\"ride\", \"rides\", \"riding\"]\n",
    "for w in some_words:\n",
    "    print (porter_stemmer.stem(w))\n",
    "\n",
    "# Let's stem all the words in our news article.\n",
    "news_words_filtered_stemmed = []\n",
    "for w in news_words_filtered:\n",
    "    news_words_filtered_stemmed.append(porter_stemmer.stem(w))\n",
    "\n",
    "print (news_words_filtered_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Section 7 ###############\n",
    "# Word Cloud takes a string. Convert our list of words into a string.\n",
    "words_joined = \" \".join([w for w in news_words_filtered_stemmed])\n",
    "\n",
    "# Create a word cloud\n",
    "my_wordcloud = WordCloud(background_color='white',\n",
    "                         width=1800,\n",
    "                         height=1400).generate(words_joined)\n",
    "\n",
    "plt.imshow(my_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "#plt.savefig('WordCloud.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTANT\n",
    "\n",
    "For Linux OS, you need to change the font_path to point to the OTF file in your Linux directory.\n",
    "'''\n",
    "\n",
    "############### Section 8 ###############\n",
    "# Create a word cloud\n",
    "my_wordcloud = WordCloud(\n",
    "    background_color='black',\n",
    "    width=1800,\n",
    "    height=1400,\n",
    "    font_path='C:\\\\Windows\\\\Fonts\\\\CabinSketch-Bold.otf').generate(words_joined)\n",
    "\n",
    "plt.imshow(my_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "#plt.savefig('WordCloud2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
