{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Crawling & Scraping (Web Scraping from a Blog page)\n",
    "\n",
    "Web Scraping using Python\n",
    "\n",
    "We use BeautifulSoup package in Python - to perform web scraping, whereby\n",
    "we attempt to extract out only certain text content.\n",
    "\n",
    "In this lab, we attempt to scrape a local Singaporean influencer's blog content at this site:\n",
    "http://www.mongabong.com/2017/08/largest-executive-condo-sol-acres.html\n",
    "\n",
    "We are particularly interested in extracting a given blog entry's:\n",
    "1. Title\n",
    "2. Date (of entry)\n",
    "3. Blog content (essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 1 ########\n",
    "'''\n",
    "1) requests\n",
    "--> we use this module to make HTTP request to go and download a webpage\n",
    "2) BeautifulSoup\n",
    "--> we use this module to parse out text from HTML content\n",
    "'''\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 2 ########\n",
    "'''\n",
    "Later on, you will need to modify this script to read MULTIPLE HTML files from a directory.\n",
    "For now, we're going to connect to the blogger's blog entry via HTTP.\n",
    "To do that, we simply specify the blog entry's URL.\n",
    "'''\n",
    "source_path = \"http://www.mongabong.com/2017/08/largest-executive-condo-sol-acres.html\"\n",
    "page = requests.get(source_path)\n",
    "page_content = page.content # http response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 3 ########\n",
    "'''\n",
    "The way BeautifulSoup works is... you need to grab the webpage's HTML content\n",
    "--> page.content\n",
    "\n",
    "And then, you need to tell BeautifulSoup that you want it to \"parse\" page's HTML content\n",
    "--> 'html.parser'\n",
    "'''\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "'''\n",
    "prettify() function will do indentation so that the extracted HTML content has\n",
    "HTML tags nicely indented for easy viewing.\n",
    "Try uncommenting the below line and print.\n",
    "'''\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Retrieve blog title\n",
    "# <div class=\"post-header\"> --> <h1>\n",
    "\n",
    "h1_items = soup.find_all('h1')\n",
    "#print(h1_items)\n",
    "\n",
    "title = h1_items[1].text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Retrieve blog date\n",
    "# <span class=\"date\">Friday, August 25, 2017</span>\n",
    "\n",
    "date_span = soup.find('span', class_=\"date\")\n",
    "#print(date_span.text)\n",
    "date_text = date_span.text\n",
    "print(date_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Retrieve the article content (excluding photos)\n",
    "\n",
    "divs = soup.find_all('div', class_=\"separator\")\n",
    "#print(divs)\n",
    "\n",
    "for div in divs:\n",
    "    print(\"---\")\n",
    "    print(div.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 4 ########\n",
    "'''\n",
    "This line calls find_all() function to look for 'div' tag with class='post-header'.\n",
    "find_all() returns us a LIST.\n",
    "\n",
    "What we want is the FIRST item in this LIST.\n",
    "\n",
    "As you know... in Python (and in many other programming languages),\n",
    "the FIRST guy in a list/array has the INDEX value of 0 (zero).\n",
    "So, we're going to add [0] to the end of the line - to extract the FIRST div with class='post-header'.\n",
    "\n",
    "Why are we interested in extracting this div?\n",
    "\n",
    "Inside this div... are: 1) title, 2) date of the blog entry.\n",
    "\n",
    "this div... looks like this\n",
    "\n",
    "<div class=\"post-header\">\n",
    "    <h1>\n",
    "        First Home- Singapore's Largest Development EC, Sol Acres\n",
    "    </h1>\n",
    "    <span class=\"date\">Friday, August 25, 2017</span>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "# retrieve all elements with class='post-header'\n",
    "title_date_div = soup.find('div', class_='post-header') # not a list, object\n",
    "print(post_header)\n",
    "\n",
    "title_element = post_header.find('h1')\n",
    "print(\"-------\")\n",
    "print(title_element.text)\n",
    "\n",
    "# title_date_div = soup.find_all('div', class_='post-header')[0]\n",
    "# print(title_date_div)\n",
    "\n",
    "date_text = post_header.find('span')\n",
    "print(date_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 5 ########\n",
    "'''\n",
    "title_date_div contains what we want... 1) title and 2) date.\n",
    "\n",
    "<div class=\"post-header\">\n",
    "    <h1>\n",
    "        First Home- Singapore's Largest Development EC, Sol Acres\n",
    "    </h1>\n",
    "    <span class=\"date\">Friday, August 25, 2017</span>\n",
    "</div>\n",
    "\n",
    "We need to extract out the blog entry's \"title\", inside <h1>.\n",
    "How do we get ... just the TEXT portion ... inside <h1> ... </h1>?\n",
    "\n",
    "First, we need to find h1 tag inside the div.\n",
    "--> find('h1')\n",
    "\n",
    "After this, to extract just the TEXT portion... we call get_text() function.\n",
    "Try this and print. See what you get.\n",
    "'''\n",
    "title = title_date_div.find('h1').get_text()\n",
    "# In case... the title content has end-of-line (\\n), we don't want it - we want it removed.\n",
    "# We use replace() function to replace (if any) '\\n' (end-of-line character) with empty string ('').\n",
    "title = title.replace('\\n', '')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 6 ########\n",
    "'''\n",
    "Same thing here.. we need to get \"date\" of this blog entry.\n",
    "\n",
    "<div class=\"post-header\">\n",
    "    <h1>\n",
    "        First Home- Singapore's Largest Development EC, Sol Acres\n",
    "    </h1>\n",
    "    <span class=\"date\">Friday, August 25, 2017</span>\n",
    "</div>\n",
    "\n",
    "The \"date\" we want... is inside <span>... </span>.\n",
    "--> find('span')\n",
    "This finds us <span>...</span>.\n",
    "Note that you can also... look for a tag with class=\"date\" by doing:\n",
    "--> find(class_='date')\n",
    "Either way is fine.\n",
    "\n",
    "Once you get the span... call get_text() function to extract the TEXT portion,\n",
    "which is essentially what we want --> blog entry's DATE. :)\n",
    "\n",
    "Try the below code and see what you get.\n",
    "'''\n",
    "date = title_date_div.find('span').get_text()\n",
    "#date = title_date_div.find(class_='date').get_text()\n",
    "# In case... the date content has end-of-line (\\n), we don't want it - we want it removed.\n",
    "# We use replace() function to replace (if any) '\\n' (end-of-line character) with empty string ('').\n",
    "date = date.replace('\\n', '')\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 7 ########\n",
    "'''\n",
    "Here, we need to capture blog's main content (essay portion).\n",
    "\n",
    "If you look at the HTML content... you'll see that the blogger's article consists of\n",
    "a series of:\n",
    "\n",
    " <div class=\"separator\" style=\"clear: both; text-align: center;\">\n",
    "    some content...\n",
    " </div>\n",
    "\n",
    "On her website, the content looks like a contiguous block of text but the HTML isn't.\n",
    "So, we need BeautifulSoup to extract ALL ... <div class=\"separator\"> tags.\n",
    "\n",
    "When it does, it will insert all matched entries into a LIST.\n",
    "'''\n",
    "essay_div = soup.find_all('div', class_='separator')\n",
    "\n",
    "for para in essay_div:\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What we'll do now... is to LOOP THRU this LIST of <div class=\"separator\"> tags...\n",
    "and extract out the TEXT portion.\n",
    "One by one...as we extract out the TEXT portion of the tag, we will append it to essay_content text variable.\n",
    "\n",
    "In the end, essay_content will contain the ENTIRE blog entry's essay portion.\n",
    "'''\n",
    "\n",
    "# We initialize essay_content string... to an empty string.\n",
    "essay_content = \"\"\n",
    "\n",
    "# We LOOP THRU the list of div tags...\n",
    "for segment in essay_div:\n",
    "    # segment is a div object - we need to extract out the TEXT portion by calling get_text() function.\n",
    "    segment_text = segment.get_text()\n",
    "    # If the TEXT portion contains end-of-line character (\\n), remove it.\n",
    "    # We use replace() function to do this operation.\n",
    "    segment_text = segment_text.replace('\\n', '')\n",
    "\n",
    "    # If the extracted TEXT portion after stripping off \\n ... is NOT empty, then it must be\n",
    "    # containing some essay content... so append it to essay_content string.\n",
    "    if segment_text != \"\":\n",
    "        #print(segment_text)\n",
    "        essay_content = essay_content + segment_text + ' '\n",
    "\n",
    "'''\n",
    "We're done grabbing all the essay content.\n",
    "Let's print and see what it looks like.\n",
    "'''\n",
    "print (essay_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
