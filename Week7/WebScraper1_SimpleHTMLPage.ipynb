{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Crawling & Scraping (Web Scraping from an HTML page)\n",
    "\n",
    "Web Scraping using Python\n",
    "\n",
    "We use BeautifulSoup package in Python - to perform web scraping, whereby\n",
    "we attempt to extract out only certain text content.\n",
    "\n",
    "In this lab, we are particularly interested in extracting Supreme Leader's welcome message at this site:\n",
    "http://krazywoman.com/index.html\n",
    "\n",
    "The above index.html page has the following HTML content.\n",
    "Our objective is to extract out the text content enclosed with <p> and </p> tags.\n",
    "There are 2 pairs of them.\n",
    "\n",
    "<html>\n",
    "<head>\n",
    "<title>Supreme Leader's Home</title>\n",
    "</head>\n",
    "\n",
    "<body bgcolor=\"black\">\n",
    "\n",
    "<center>\n",
    "<font color=\"white\">\n",
    "\n",
    "    <h1>Supreme Leader's Online Home</h1>\n",
    "    <h2>World's Best Leader</h2>\n",
    "    <h3>Seriously, I am.</h3>\n",
    "\n",
    "    <p>Welcome to my homepage. You didn't know I had a homepage, right? Well, I do and now you know.</p>\n",
    "    <p>Browse around and see if you can find any interesting articles I've been writing in my Supreme Palace.</p>\n",
    "\n",
    "</font>\n",
    "</center>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 1 ########\n",
    "'''\n",
    "1) requests\n",
    "--> we use this module to make HTTP request to go and download a webpage\n",
    "2) BeautifulSoup\n",
    "--> we use this module to parse out text from HTML content\n",
    "'''\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 2 ########\n",
    "'''\n",
    "Connect to Supreme Leader's homepage (index.html is the main page).\n",
    "To do that, we simply specify the blog entry's URL.\n",
    "'''\n",
    "source_path = 'http://krazywoman.com/index.html'\n",
    "page = requests.get(source_path) # http request\n",
    "page_content = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 3 ########\n",
    "'''\n",
    "The way BeautifulSoup works is... you need to grab the webpage's HTML content\n",
    "--> page.content\n",
    "\n",
    "And then, you need to tell BeautifulSoup that you want it to \"parse\" page's HTML content\n",
    "--> 'html.parser'\n",
    "'''\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "'''\n",
    "prettify() function will do indentation so that the extracted HTML content has\n",
    "HTML tags nicely indented for easy viewing.\n",
    "Try uncommenting the below line and print.\n",
    "'''\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find <title>\n",
    "title = soup.find('title')\n",
    "print(title)\n",
    "print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find <h1>\n",
    "heading1 = soup.find('h1')\n",
    "print(heading1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all instances of <p>\n",
    "paras = soup.find_all('p')\n",
    "print(paras)\n",
    "\n",
    "for para in paras:\n",
    "    print(\"----\")\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a <p>\n",
    "# Note that unlike find_all()\n",
    "#   find() returns the 1st found instance of <p>\n",
    "\n",
    "para = soup.find('p')\n",
    "print(para)\n",
    "print(para.get_text()) # strip off HTML tags, give u text\n",
    "print(para.text) # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 4 ########\n",
    "'''\n",
    "This line calls find_all() function to look for one or more 'p' (paragraph) tags.\n",
    "--> When one or more 'p' tags are found, find_all() function returns us a LIST of bs4.element.Tag objects.\n",
    "'''\n",
    "results_list = soup.find_all('p')\n",
    "\n",
    "# Let's see what the search results look like\n",
    "print(results_list)\n",
    "#print(results_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 5 ########\n",
    "'''\n",
    "If you look at the list, <p> and </p> tags are still found.\n",
    "We need to remove these HTML tags.\n",
    "\n",
    "To do that, we use get_text() function off each result object (bs4.element.Tag).\n",
    "get_text() function strips off HTML tags and just returns the text content!\n",
    "\n",
    "We will store these text content as strings in a new LIST called 'messages'.\n",
    "'''\n",
    "text_list = []\n",
    "for result in results_list:\n",
    "    #print(type(result)) # Uncomment this and you can see that each item in the list is of bs4.element.Tag type.\n",
    "    print(result.get_text())\n",
    "    text_list.append(result.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 6 ########\n",
    "'''\n",
    "Let's put together the two paragraph texts into a single string.\n",
    "We will use join function to concatenate/append/join two strings.\n",
    "'''\n",
    "final_message = \" \".join(str(n) for n in text_list)\n",
    "\n",
    "# Let's see if we have the two \n",
    "print(final_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
