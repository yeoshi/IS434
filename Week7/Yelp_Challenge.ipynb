{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Crawling & Scraping (Web Scraping from a Yelp page) - CODING CHALLENGE !!!\n",
    "\n",
    "Web Scraping using Python\n",
    "\n",
    "We use BeautifulSoup package in Python - to perform web scraping, whereby\n",
    "we attempt to extract out only certain text content.\n",
    "\n",
    "In this lab, we attempt to scrape a Yelp restaurant review page.\n",
    "We chose the Din Tai Fung restaurant in Raffles City Shopping Centre.\n",
    "https://www.yelp.com/biz/din-tai-fung-singapore-4?osq=Restaurants\n",
    "\n",
    "We attemp to extract the restaurant reviews. In particular, we are interested in:\n",
    "1. Reviewer's name\n",
    "2. Reviewer's location\n",
    "3. Review score (star rating)\n",
    "4. Review comment\n",
    "\n",
    "Please note that there are many 'pages' of reviews.\n",
    "If you scroll down to the bottom of the page, you will see that the current page is 1.\n",
    "And, you can click on \"2\" to navigate to another page of reviews.\n",
    "You can click on \"3\" to navigate to another page of reviews.\n",
    "And so on...\n",
    "\n",
    "In this lab exercise, we are only interested in the FIRSTE page and want to web scrape from this 1st page ONLY.\n",
    "In order to programmatically download reviews from multiple pages, we will have to resort to \"web crawling\".\n",
    "You will need to use a package called 'Selenium' for this.\n",
    "\n",
    "\n",
    "*** CODING CHALLENGE ***\n",
    "The script below... attempts to retrieve only the 1st review. And some parts of the code may need further debugging.\n",
    "\n",
    "1. Modify the code to extract out ALL reviews on the 1st page.\n",
    "\n",
    "2. Output the extracted reviews in this format.\n",
    "- 1st row of the output file is the header (author_name, author_location, review_rating, review_comment).\n",
    "- 2nd row onwards must contain actual data.\n",
    "- The output is TAB delimited.\n",
    "- You do not have to put double quotation marks around each value.\n",
    "- Please note that the review comment must be a single/one string value. Make sure to append multiple lines of text into single/one string.\n",
    "\n",
    "If you can write the entire code in a more efficient and cleaner manner, by all means -\n",
    "Please do so.\n",
    "\n",
    "If and when you are done with the coding challenge, please kindly check Slack #troubleshoot channel\n",
    "and help guide others struggling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 1 ########\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 2 ########\n",
    "'''\n",
    "Let's use Selenium to visit Yelp restaurant review webpage\n",
    "'''\n",
    "review_webpage_url = \"https://www.yelp.com/biz/din-tai-fung-singapore-4?osq=Restaurants\"\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(review_webpage_url)\n",
    "Pagelength = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 3 ########\n",
    "'''\n",
    "We can now use BeautifulSoup to inspect the HTML\n",
    "'''\n",
    "source = browser.page_source\n",
    "data = bs(source, 'html.parser')\n",
    "\n",
    "body = data.find('body')\n",
    "\n",
    "'''\n",
    "prettify() function will do indentation so that the extracted HTML content has\n",
    "HTML tags nicely indented for easy viewing.\n",
    "Try uncommenting the below line and print.\n",
    "'''\n",
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 4 ########\n",
    "'''\n",
    "Get reviewer's name\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 5 ########\n",
    "'''\n",
    "Get reviewer's location\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 6 ########\n",
    "'''\n",
    "Get review (star) rating\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 7 ########\n",
    "'''\n",
    "Get review text\n",
    "\n",
    "If there are multiple sentences/paragraphs, append them into a single String variable.\n",
    "print it so that we can see in the output console.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
